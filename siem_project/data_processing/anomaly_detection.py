# File: data_processing/anomaly_detection.py

from django.db.models import Avg, StdDev
from django.conf import settings
from .models import SecurityEvent, ProcessedData, AggregatedMetric
from django.utils import timezone
from datetime import timedelta
from sklearn.ensemble import IsolationForest
import numpy as np
from alert_engine.models import Alert, AlertRule

def extract_features(event):
    return [
        event.severity,
        len(event.description),
        # Add more relevant features here
    ]

def ml_anomaly_detection():
    # Get events from the last 24 hours
    start_time = timezone.now() - timedelta(hours=24)
    events = SecurityEvent.objects.filter(timestamp__gte=start_time)
    
    if not events.exists():
        return []  # Return empty list if no events

    # Extract features (you may need to adjust this based on your data)
    features = np.array([[
        event.severity,
        int(event.event_type == 'LOGIN'),
        int(event.event_type == 'FIREWALL'),
        # Add more features as needed
    ] for event in events])
    
    # Check if we have enough data
    if len(features) < 10:  # Adjust this threshold as needed
        return []  # Not enough data for meaningful anomaly detection
    
    try:
        # Initialize and fit the model
        model = IsolationForest(contamination=0.1, random_state=42)
        results = model.fit_predict(features)
        
        # Identify anomalies
        anomalies = [event for event, result in zip(events, results) if result == -1]
        return anomalies
    except Exception as e:
        print(f"Error in ML anomaly detection: {str(e)}")
        return []  # Return empty list if an error occurs

def calculate_cvss_score(security_event):
    return min(10, security_event.severity * 2.5)  # Assuming severity is 1-4

def detect_anomalies(security_event):
    cvss_score = calculate_cvss_score(security_event)
    
    last_24_hours = timezone.now() - timedelta(hours=24)
    historical_data = ProcessedData.objects.filter(
        security_event__event_type=security_event.event_type,
        security_event__timestamp__gte=last_24_hours
    )

    ml_anomalies = ml_anomaly_detection()
    is_ml_anomaly = security_event in ml_anomalies

    risk_score = cvss_score

    avg_score = historical_data.aggregate(Avg('risk_score'))['risk_score__avg'] or cvss_score
    std_dev = historical_data.aggregate(StdDev('risk_score'))['risk_score__stddev'] or 1
    
    is_anomaly = abs(cvss_score - avg_score) > (1 if settings.TEST_MODE else 2) * std_dev
    
    final_is_anomaly = is_anomaly or is_ml_anomaly
    final_risk_score = max(risk_score, 8.0 if is_ml_anomaly else risk_score)
    
    final_risk_score = cvss_score * 1.5 if final_is_anomaly else cvss_score
    
    if final_is_anomaly:
        # Create an alert for the detected anomaly
        alert_rule, _ = AlertRule.objects.get_or_create(
            name="ML Anomaly Detection",
            defaults={
                "description": "Alert generated by ML-based anomaly detection",
                "condition": "ML_ANOMALY",
                "severity": 3  # High severity for ML-detected anomalies
            }
        )
        Alert.objects.create(
            rule=alert_rule,
            title=f"Anomaly Detected: {security_event.event_type}",
            description=f"Anomaly detected for event {security_event.event_id}. Risk score: {final_risk_score}",
            severity=alert_rule.severity,
            created_at=timezone.now(),
            status='New'
        )
    
    return round(final_risk_score, 2), final_is_anomaly

def update_aggregated_metrics(event_type, risk_score, is_anomaly):
    current_time = timezone.now()
    start_of_hour = current_time.replace(minute=0, second=0, microsecond=0)
    end_of_hour = start_of_hour + timedelta(hours=1)
    
    AggregatedMetric.objects.update_or_create(
        metric_name=f"{event_type}_avg_risk_score",
        start_time=start_of_hour,
        end_time=end_of_hour,
        defaults={
            'metric_value': risk_score,
            'dimension': {'event_type': event_type}
        }
    )
    
    if is_anomaly:
        AggregatedMetric.objects.update_or_create(
            metric_name=f"{event_type}_anomaly_count",
            start_time=start_of_hour,
            end_time=end_of_hour,
            defaults={
                'metric_value': 1,
                'dimension': {'event_type': event_type}
            }
        )

def run_ml_anomaly_detection():
    anomalies = ml_anomaly_detection()
    for anomaly in anomalies:
        detect_anomalies(anomaly)  # This will now create alerts for each anomaly
    return len(anomalies)
